# 图床项目面试问题总结与解答

## 项目来源说明

**如果面试官问：你这个项目是从哪里来的？**

**回答：**
这是一个基于零声教育课程学习的图床项目，我在学习过程中深入理解了其架构设计，并在此基础上进行了优化和扩展。项目采用C++实现，使用了Reactor网络模型、线程池、连接池等核心技术，是一个完整的分布式文件存储系统。

---

## 1. 项目框架

**问题：请介绍一下项目的整体框架？**

**回答：**
项目采用**Reactor网络模型 + 线程池**的架构：

1. **网络层**：基于epoll的Reactor模式，主线程负责监听和IO事件分发
2. **业务处理层**：使用线程池处理HTTP请求，避免阻塞主线程
3. **数据存储层**：
   - FastDFS：分布式文件存储系统，存储实际文件
   - MySQL：存储文件元数据（MD5、URL、文件信息等）
   - Redis：缓存热点数据，实现排行榜功能
4. **连接池**：MySQL和Redis都使用连接池管理，提高性能
5. **日志系统**：使用spdlog进行日志记录

**核心流程**：
- 客户端上传文件 → HTTP服务器接收 → 线程池处理 → 计算MD5 → 上传FastDFS → 存储元数据到MySQL → 返回URL

---

## 2. 存储有没有可能会丢数据

**问题：存储有没有可能会丢数据？有没有可能同步给其他机器？如果换成更强的方案，mini版本存储怎么处理？**

**回答：**

### 2.1 数据丢失风险

**FastDFS的可靠性机制：**
1. **副本机制**：FastDFS支持配置副本数量（replica count），默认情况下文件会被复制到多个Storage节点
2. **同步机制**：Storage节点之间会自动同步文件，确保数据一致性
3. **Tracker高可用**：可以配置多个Tracker节点，避免单点故障

**可能丢数据的情况：**
- 所有副本节点同时故障（概率极低）
- 网络分区导致同步失败
- 磁盘故障且副本未及时同步

### 2.2 同步机制

FastDFS的同步是**自动推送**的：
- 当文件上传到Storage节点后，该节点会主动将文件推送到同组的其他Storage节点
- 同步是异步进行的，通过binlog机制保证最终一致性
- 可以通过配置`sync_wait_msec`参数控制同步等待时间

### 2.3 更强的存储方案

如果要换成更强的方案，可以考虑：
1. **对象存储**：阿里云OSS、腾讯云COS、AWS S3等，提供99.999999999%的持久性
2. **分布式存储**：Ceph、MinIO等，支持多副本、纠删码
3. **数据库存储**：对于小文件可以考虑直接存储在数据库（BLOB），但性能较差

### 2.4 Mini版本存储处理

Mini版本如果要简化存储：
- 可以使用本地文件系统存储
- 或者使用单机版FastDFS
- 对于演示项目，可以只存储文件路径，不存储实际文件内容

---

## 3. 是否可以不使用upload接口

**问题：是否可以不使用upload接口？**

**回答：**

**可以，但需要权衡：**

1. **直接上传到FastDFS**：
   - 优点：减少服务器压力，客户端直接与Storage通信
   - 缺点：无法进行业务逻辑处理（如MD5校验、权限控制、元数据管理）

2. **使用upload接口的优势**：
   - 可以进行文件校验（MD5、大小、类型）
   - 可以实现权限控制
   - 可以记录上传日志和统计
   - 可以实现文件去重（相同MD5只存储一份）
   - 可以生成短链、分享链接等

3. **混合方案**：
   - 小文件：通过upload接口，进行业务处理
   - 大文件：客户端先获取上传token，然后直接上传到FastDFS，最后回调通知服务器

**本项目使用upload接口的原因**：
- 需要计算MD5进行文件去重
- 需要将文件信息存储到MySQL
- 需要支持文件分享、短链等功能

---

## 4. HTTP上传流

**问题：HTTP上传流是怎么处理的？HTTP怎么判断请求？请求过大怎么处理？怎么判断请求完整性？**

**回答：**

### 4.1 HTTP请求处理流程

```cpp
// 1. 接收HTTP请求头
void CHttpConn::OnRead() {
    // 从socket读取数据到in_buf_
    // 使用http_parser解析HTTP协议
    // 判断Content-Length确定请求体大小
}

// 2. 解析multipart/form-data格式
int _HandleUploadRequest(string &url, string &post_data) {
    // 解析boundary分隔符
    // 提取file_name、file_content_type、file_path等字段
    // 读取文件内容
}
```

### 4.2 判断请求完整性

1. **通过Content-Length**：
   - HTTP请求头中包含`Content-Length`字段，表示请求体的总长度
   - 服务器读取数据直到达到Content-Length指定的长度

2. **通过boundary判断**（multipart/form-data）：
   - 使用`------WebKitFormBoundaryxxx`作为分隔符
   - 读取到结束boundary（`------WebKitFormBoundaryxxx--`）表示请求完成

3. **超时机制**：
   - 设置连接超时时间（HTTP_CONN_TIMEOUT = 60000ms）
   - 如果超过时间未收到完整请求，关闭连接

### 4.3 请求过大处理

**当前实现**：
- 使用缓冲区`CSimpleBuffer`逐步读取
- 缓冲区大小：`READ_BUF_SIZE = 2048`字节

**优化方案**：
1. **流式处理**：
   - 边读边写，不全部加载到内存
   - 使用临时文件存储大文件内容

2. **分块上传**：
   - 支持HTTP分块传输（Transfer-Encoding: chunked）
   - 客户端分块上传，服务器合并

3. **限制大小**：
   - 在HTTP头解析阶段就检查Content-Length
   - 超过限制直接拒绝（如100MB）

4. **异步处理**：
   - 大文件上传放到后台线程处理
   - 返回任务ID，客户端轮询状态

---

## 5. MD5有没有碰撞

**问题：MD5有没有碰撞？如何避免？**

**回答：**

### 5.1 MD5碰撞问题

**理论上的碰撞**：
- MD5算法已经被证明存在碰撞漏洞
- 可以构造两个不同的文件产生相同的MD5值
- 但实际应用中，自然碰撞的概率极低（约2^64分之一）

**实际风险**：
- **恶意碰撞**：攻击者可能故意构造碰撞文件
- **文件去重误判**：不同文件被误认为相同文件

### 5.2 解决方案

1. **使用更强的哈希算法**：
   - SHA-256：更安全，但计算稍慢
   - SHA-512：安全性最高
   - 本项目可以升级为SHA-256

2. **多重校验**：
   - MD5 + 文件大小
   - MD5 + SHA1
   - MD5 + 文件前1KB的哈希

3. **业务层校验**：
   - 即使MD5相同，也检查文件大小
   - 对于关键文件，进行内容对比

4. **本项目当前方案**：
   - 使用MD5 + 文件大小进行去重判断
   - 对于图片分享等场景，MD5碰撞风险可接受

---

## 6. Redis怎么用

**问题：Redis在项目中怎么使用？排行榜zset怎么实现？怎么知道哪个文件最热门？后端有两个请求都去redis请求怎么办？**

**回答：**

### 6.1 Redis使用场景

1. **缓存文件信息**：
   - 缓存通过urlmd5查询的图片分享信息
   - 减少MySQL查询压力

2. **排行榜**（ZSET）：
   - 使用有序集合存储文件下载排行
   - Key: `FILE_PUBLIC_ZSET`
   - Score: 下载次数（PV）
   - Member: 文件MD5

3. **计数器**：
   - 共享文件数量：`FILE_PUBLIC_COUNT`
   - 用户文件数量：`FILE_USER_COUNT+username`
   - 分享图片数量：`SHARE_PIC_COUNT+username`

4. **Hash存储**：
   - 文件MD5到文件名的映射：`FILE_NAME_HASH`
   - Field: file_id(md5)
   - Value: file_name

### 6.2 排行榜实现（ZSET）

```cpp
// 1. 添加文件到排行榜
ZADD FILE_PUBLIC_ZSET score member
// score = 下载次数，member = 文件MD5

// 2. 增加下载次数
ZINCRBY FILE_PUBLIC_ZSET 1 member
// 每次下载，score +1

// 3. 获取排行榜
ZREVRANGE FILE_PUBLIC_ZSET 0 9 WITHSCORES
// 获取前10名，按score降序排列

// 4. 获取某个文件的排名
ZREVRANK FILE_PUBLIC_ZSET member
// 返回排名（从0开始）
```

**实现细节**：
- 当文件被分享时，添加到ZSET，初始score=1
- 每次下载，使用`ZINCRBY`增加score
- 查询排行榜时，使用`ZREVRANGE`获取top N

### 6.3 如何知道最热门文件

1. **实时查询**：
   ```cpp
   // 获取下载量最高的文件
   ZREVRANGE FILE_PUBLIC_ZSET 0 0 WITHSCORES
   // 返回score最高的文件MD5
   ```

2. **定期更新**：
   - 可以设置定时任务，定期将Redis排行榜同步到MySQL
   - 或者直接查询Redis，性能更好

3. **缓存策略**：
   - 将top 10的排行榜结果缓存
   - 设置过期时间，定期刷新

### 6.4 并发请求处理

**问题场景**：两个请求同时访问Redis，可能导致数据不一致

**解决方案**：

1. **Redis原子操作**：
   - `ZINCRBY`是原子操作，多个请求并发执行不会出错
   - Redis单线程模型保证操作的原子性

2. **分布式锁**（如果需要复杂逻辑）：
   ```cpp
   // 使用Redis实现分布式锁
   SET lock_key unique_value NX EX 10
   // NX: 只在key不存在时设置
   // EX: 设置过期时间
   ```

3. **连接池**：
   - 使用Redis连接池，避免连接竞争
   - 本项目使用`CacheManager`管理Redis连接

4. **读写分离**：
   - 读操作可以使用多个Redis连接
   - 写操作使用主Redis，保证一致性

---

## 7. 分布式锁

**问题：项目中是否使用了分布式锁？如何实现？**

**回答：**

### 7.1 当前项目中的锁

**本地锁**：
- 使用`std::mutex`保护共享资源
- 线程池任务队列使用mutex + condition_variable
- 连接池使用mutex保护连接列表

**分布式锁场景**：
- 如果需要多服务器部署，需要考虑分布式锁
- 例如：防止同一文件被多个服务器重复处理

### 7.2 分布式锁实现方案

**基于Redis实现**：

```cpp
// 1. 获取锁
bool acquireLock(const string& lock_key, const string& unique_value, int expire_time) {
    // SET lock_key unique_value NX EX expire_time
    // NX: 只在key不存在时设置
    // EX: 设置过期时间，防止死锁
    // unique_value: 唯一标识，用于释放锁时验证
}

// 2. 释放锁（Lua脚本保证原子性）
bool releaseLock(const string& lock_key, const string& unique_value) {
    // if redis.call("get", KEYS[1]) == ARGV[1] then
    //     return redis.call("del", KEYS[1])
    // else
    //     return 0
    // end
}
```

**关键点**：
1. **唯一值**：使用UUID或线程ID，确保只有加锁的进程能解锁
2. **过期时间**：防止进程崩溃导致死锁
3. **原子性**：使用Lua脚本保证检查和删除的原子性
4. **重试机制**：获取锁失败时，可以重试或直接返回

**应用场景**：
- 文件上传去重：多个服务器同时处理相同MD5的文件
- 排行榜更新：防止并发更新导致数据错误
- 缓存更新：防止缓存击穿

---

## 8. 负载均衡部署

**问题：如何实现负载均衡部署？**

**回答：**

### 8.1 部署架构

```
                    Nginx (负载均衡)
                    /      |      \
            Server1    Server2    Server3
            (8081)     (8082)     (8083)
               |          |          |
            MySQL主从   Redis集群   FastDFS集群
```

### 8.2 Nginx配置

```nginx
upstream backend {
    server 127.0.0.1:8081;
    server 127.0.0.1:8082;
    server 127.0.0.1:8083;
}

server {
    listen 80;
    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # 大文件上传
    client_max_body_size 100m;
}
```

### 8.3 负载均衡策略

1. **轮询**（Round Robin）：默认方式
2. **加权轮询**：根据服务器性能分配权重
3. **IP哈希**：相同IP总是访问同一服务器（保持会话）
4. **最少连接**：优先分配给连接数最少的服务器

### 8.4 需要考虑的问题

1. **会话保持**：
   - 如果使用token认证，需要共享Redis存储token
   - 或者使用IP哈希保证同一用户访问同一服务器

2. **文件上传**：
   - 大文件上传可能超时，需要调整Nginx超时时间
   - 或者使用分块上传

3. **数据一致性**：
   - MySQL使用主从复制，写操作走主库，读操作走从库
   - Redis可以使用集群模式

4. **健康检查**：
   - Nginx可以配置健康检查，自动剔除故障服务器
   - 或者使用Keepalived实现高可用

---

## 9. 网络框架

**问题：如果你实现这个网络框架，你给别人提供什么接口？细节问题：main reactor和sub reactor+线程池的线程数量如何设置？智能指针在哪里使用，三种智能指针用在哪里，为什么这么用？定时器map如何实现？网络缓冲区如何设计？**

**回答：**

### 9.1 网络框架提供的接口

**核心接口**：

1. **监听接口**：
   ```cpp
   int netlib_listen(const char* server_ip, uint16_t port, 
                     callback_t callback, void* callback_data);
   // 监听指定IP和端口，新连接到来时调用callback
   ```

2. **注册连接建立/断开回调**：
   ```cpp
   void http_callback(void *callback_data, uint8_t msg, uint32_t handle, void *pParam);
   // msg: NETLIB_MSG_CONNECT - 新连接
   //      NETLIB_MSG_CLOSE - 连接关闭
   ```

3. **注册recv回调**（数据已在内部读取）：
   ```cpp
   void OnRead();
   // 当有数据可读时，框架自动调用
   // 数据已经读取到in_buf_中
   ```

4. **数据发送接口**：
   ```cpp
   int Send(void *data, int len);
   // 发送数据，如果发送缓冲区满，会注册写事件，等待可写时继续发送
   ```

5. **事件循环**：
   ```cpp
   void netlib_eventloop(uint32_t wait_timeout);
   // 主事件循环，处理epoll事件
   ```

### 9.2 Main Reactor + Sub Reactor + 线程池

**架构设计**：

```
Main Reactor (主线程)
    ↓ accept新连接
Sub Reactor (IO线程，可选)
    ↓ 分发到线程池
Thread Pool (工作线程)
    ↓ 处理业务逻辑
```

**线程数量设置**：

1. **Main Reactor**：1个线程
   - 负责accept新连接
   - 负责epoll事件分发

2. **Sub Reactor**（可选）：
   - 如果使用，通常设置为CPU核心数
   - 每个Sub Reactor处理一部分连接的IO事件

3. **线程池**：
   - **CPU密集型**：线程数 = CPU核心数
   - **IO密集型**：线程数 = CPU核心数 × 2
   - **本项目**：配置文件可设置，默认4-8个线程

**本项目实现**：
- 使用**单Reactor + 线程池**模式
- Main Reactor处理所有IO事件
- 业务处理交给线程池

### 9.3 智能指针使用

**三种智能指针及其使用场景**：

1. **unique_ptr**（独占所有权）：
   ```cpp
   // 用于临时缓冲区，函数结束时自动释放
   std::unique_ptr<char[]> buf(new char[size]);
   // 用于gRPC客户端
   std::unique_ptr<ShortUrl::Stub> stub_;
   ```
   **使用场景**：
   - 临时缓冲区（如读取HTTP body）
   - 函数局部对象，不需要共享
   - 移动语义，避免拷贝

2. **shared_ptr**（共享所有权）：
   ```cpp
   // 日志系统
   std::shared_ptr<spdlog::logger> log_;
   // 线程池任务
   typedef shared_ptr<TaskFunc> TaskFuncPtr;
   // gRPC Channel
   std::shared_ptr<::grpc::ChannelInterface> channel_;
   ```
   **使用场景**：
   - 多个对象需要共享同一资源
   - 日志系统（多个模块共享logger）
   - 线程池任务（任务可能被多个线程访问）

3. **weak_ptr**（弱引用）：
   ```cpp
   // 本项目未直接使用，但可以用于：
   // 1. 打破循环引用
   // 2. 观察者模式
   std::weak_ptr<CHttpConn> conn_weak;
   ```
   **使用场景**：
   - 打破shared_ptr的循环引用
   - 观察者模式，不拥有对象所有权
   - 缓存系统，不阻止对象销毁

**为什么这么用**：
- **unique_ptr**：性能最好，零开销，适合独占场景
- **shared_ptr**：需要共享时使用，但有引用计数开销
- **weak_ptr**：解决循环引用问题，不增加引用计数

### 9.4 定时器实现

**当前实现**（基于链表）：

```cpp
// 定时器项
struct TimerItem {
    callback_t callback;
    void* user_data;
    uint64_t interval;      // 间隔时间
    uint64_t next_tick;   // 下次触发时间
};

// 定时器列表
list<TimerItem*> timer_list_;

// 检查定时器
void CEventDispatch::_CheckTimer() {
    uint64_t curr_tick = GetTickCount();
    for (it = timer_list_.begin(); it != timer_list_.end();) {
        TimerItem* pItem = *it;
        if (curr_tick >= pItem->next_tick) {
            pItem->callback(pItem->user_data, 0, 0, NULL);
            pItem->next_tick = curr_tick + pItem->interval;
            ++it;
        } else {
            ++it;
        }
    }
}
```

**优化方案**（时间轮）：

```cpp
// 时间轮：O(1)插入和删除
class TimeWheel {
    vector<list<TimerItem*>> wheel_[WHEEL_SIZE];
    int current_slot_;
    
    void AddTimer(TimerItem* item) {
        int slot = (current_slot_ + item->interval) % WHEEL_SIZE;
        wheel_[slot].push_back(item);
    }
    
    void Tick() {
        list<TimerItem*>& slot = wheel_[current_slot_];
        for (auto item : slot) {
            item->callback(item->user_data, 0, 0, NULL);
        }
        slot.clear();
        current_slot_ = (current_slot_ + 1) % WHEEL_SIZE;
    }
};
```

**应用场景**：
- 连接超时检测：60秒无活动则关闭连接
- 定期任务：如清理临时文件、更新缓存

### 9.5 网络缓冲区设计

**当前实现**（CSimpleBuffer）：

```cpp
class CSimpleBuffer {
    char* buffer_;
    uint32_t alloc_size_;  // 分配的大小
    uint32_t write_offset_; // 写偏移
    uint32_t read_offset_;  // 读偏移
    
    // 写入数据
    uint32_t Write(void* buf, uint32_t len);
    // 读取数据
    uint32_t Read(void* buf, uint32_t len);
};
```

**设计要点**：

1. **动态扩容**：
   - 初始大小：2048字节
   - 写入时如果空间不足，自动扩容（通常×2）

2. **读写分离**：
   - 使用read_offset和write_offset
   - 避免频繁移动数据

3. **内存管理**：
   - 使用智能指针或RAII管理内存
   - 避免内存泄漏

4. **优化方案**：
   - **零拷贝**：使用readv/writev系统调用
   - **内存池**：预分配大块内存，避免频繁malloc
   - **环形缓冲区**：固定大小，循环使用

**本项目使用**：
- `in_buf_`：接收缓冲区，存储HTTP请求
- `out_buf_`：发送缓冲区，存储HTTP响应

---

## 10. 副本是怎样推送的

**问题：FastDFS的副本是怎样推送的？**

**回答：**

### 10.1 FastDFS副本机制

**推送流程**：

1. **文件上传**：
   - 客户端上传文件到Storage节点A
   - Storage A接收文件并写入本地磁盘

2. **同步触发**：
   - Storage A将文件信息写入binlog
   - 启动同步线程，将文件推送到同组的其他Storage节点

3. **推送过程**：
   ```
   Storage A → Storage B (通过TCP连接)
   Storage A → Storage C (通过TCP连接)
   ```
   - 使用FastDFS的同步协议
   - 传输文件内容和元数据

4. **确认机制**：
   - 接收方Storage确认收到文件
   - 如果失败，会重试（可配置重试次数）

### 10.2 同步配置

**storage.conf配置**：
```conf
# 同步延迟时间（毫秒）
sync_wait_msec = 200

# 同步间隔时间（秒）
sync_interval = 86400

# 同步日志保留天数
sync_log_buff_interval = 10
```

### 10.3 同步保证

1. **最终一致性**：
   - 同步是异步的，不保证实时一致性
   - 但保证最终所有副本一致

2. **故障恢复**：
   - 如果同步失败，会记录到binlog
   - 节点恢复后，会继续同步未完成的文件

3. **读取策略**：
   - 优先从主Storage读取
   - 如果主Storage故障，从副本读取

---

## 11. 断点续传

**问题：如何实现断点续传？数据已经传输到服务器，如何存储已传输的数据？**

**回答：**

### 11.1 断点续传原理

**HTTP断点续传**：

1. **客户端请求**：
   ```
   Range: bytes=1024-2048
   ```
   表示请求文件的1024到2048字节

2. **服务器响应**：
   ```
   HTTP/1.1 206 Partial Content
   Content-Range: bytes 1024-2048/4096
   Content-Length: 1025
   ```

### 11.2 上传断点续传实现

**方案1：基于Range请求**：

```cpp
// 1. 客户端首次上传，获取upload_id
POST /api/upload/init
Response: {"upload_id": "xxx", "chunk_size": 1048576}

// 2. 分块上传
POST /api/upload/chunk
Headers: 
  Upload-ID: xxx
  Content-Range: bytes 0-1048575/5242880
Body: chunk_data

// 3. 服务器存储
- 将chunk存储到临时文件：/tmp/upload_xxx/chunk_0
- 记录已上传的chunk信息到Redis或数据库

// 4. 完成上传
POST /api/upload/complete
Headers: Upload-ID: xxx
- 合并所有chunk
- 上传到FastDFS
- 删除临时文件
```

**方案2：基于文件MD5**：

```cpp
// 1. 客户端计算文件MD5，先查询服务器
GET /api/upload/check?md5=xxx
Response: {"exists": true, "url": "..."}
// 如果存在，直接返回，无需上传

// 2. 如果不存在，分块上传
// 每块计算MD5，服务器校验
// 如果某块已存在，跳过上传
```

### 11.3 已传输数据存储

**存储方案**：

1. **临时文件**：
   ```cpp
   // 存储路径：/tmp/upload_{upload_id}/chunk_{chunk_num}
   string temp_dir = "/tmp/upload_" + upload_id;
   string chunk_file = temp_dir + "/chunk_" + chunk_num;
   // 写入chunk数据
   WriteFile(chunk_file, chunk_data);
   ```

2. **元数据存储**（Redis或MySQL）：
   ```cpp
   // Redis存储上传进度
   Key: "upload:" + upload_id
   Value: {
       "total_size": 5242880,
       "chunk_size": 1048576,
       "uploaded_chunks": [0, 1, 2, 5],  // 已上传的chunk编号
       "md5": "xxx",
       "create_time": "2024-01-01 12:00:00"
   }
   ```

3. **合并策略**：
   - **实时合并**：每收到一个chunk就合并（适合小文件）
   - **延迟合并**：所有chunk上传完成后合并（适合大文件）

### 11.4 本项目实现建议

**当前项目**：
- 未实现断点续传
- 文件一次性上传到临时目录，然后上传FastDFS

**改进方案**：
1. 支持分块上传
2. 使用Redis记录上传进度
3. 临时文件定期清理（如24小时未完成则删除）

---

## 12. 同步异步

**问题：同步连接池和异步连接池的区别？同步连接池简单但没有异步那么高效，如果要改成异步该怎么处理？TCP是同步还是异步？**

**回答：**

### 12.1 同步连接池

**当前实现**（同步阻塞）：

```cpp
// 获取连接（可能阻塞）
CDBConn* conn = db_manager->GetDBConn("tuchuang_master");
// 执行查询（阻塞等待结果）
CResultSet* result = conn->ExecuteQuery(sql);
// 处理结果
while (result->Next()) {
    // ...
}
// 归还连接
db_manager->RelDBConn(conn);
```

**特点**：
- **简单**：代码逻辑清晰，易于理解
- **阻塞**：执行SQL时线程被阻塞，无法处理其他请求
- **资源浪费**：线程等待数据库响应时，CPU空闲

### 12.2 异步连接池

**异步非阻塞**：

```cpp
// 1. 发起异步查询
AsyncQueryRequest* req = new AsyncQueryRequest();
req->sql = sql;
req->callback = [](CResultSet* result) {
    // 处理结果
};
db_manager->ExecuteQueryAsync(req);

// 2. 立即返回，不阻塞
// 线程可以处理其他请求

// 3. 查询完成后，通过回调处理结果
```

**特点**：
- **高效**：线程不阻塞，可以处理更多请求
- **复杂**：需要回调机制，代码复杂度增加
- **适用场景**：高并发、IO密集型应用

### 12.3 改成异步的处理

**方案1：使用异步MySQL客户端**：

```cpp
// 使用mysql_async或libmysqlclient的异步API
mysql_real_query_nonblocking(conn, sql, len);
// 使用epoll监听MySQL socket的可读事件
// 当有数据可读时，调用回调处理结果
```

**方案2：使用协程**：

```cpp
// 使用C++20协程或第三方库（如libco）
co_await db_manager->ExecuteQueryAsync(sql);
// 看起来像同步代码，但实际是异步执行
```

**方案3：使用消息队列**：

```cpp
// 将数据库操作放入消息队列
MessageQueue::Push(DatabaseTask{sql, callback});
// 专门的数据库线程处理
// 完成后通过回调或事件通知
```

### 12.4 TCP是同步还是异步

**TCP协议本身**：
- **同步的**：TCP是面向连接的可靠传输协议
- **数据按序到达**：保证数据顺序和可靠性

**TCP Socket操作**：
- **可以是同步或异步**，取决于如何调用：

**同步Socket**（阻塞）：
```cpp
// 默认情况下，socket是阻塞的
int n = recv(sock, buf, len, 0);  // 阻塞直到有数据
int n = send(sock, buf, len, 0);  // 阻塞直到发送完成
```

**异步Socket**（非阻塞）：
```cpp
// 设置为非阻塞
fcntl(sock, F_SETFL, O_NONBLOCK);
// recv/send立即返回
int n = recv(sock, buf, len, 0);  
// 如果n < 0 && errno == EAGAIN，表示暂无数据
// 需要等待epoll通知可读/可写
```

**本项目使用**：
- **非阻塞Socket** + **epoll**：实现异步IO
- 主线程不阻塞，通过epoll事件驱动

---

## 13. 批量处理和实时处理

**问题：批量处理和实时处理的优缺点？**

**回答：**

### 13.1 批量处理

**特点**：
- 收集一定数量的请求或达到时间阈值后，一次性处理
- 如：每100个请求或每10秒处理一次

**优点**：
1. **减少数据库压力**：
   - 批量插入：`INSERT INTO ... VALUES (...), (...), (...)`
   - 减少网络往返次数
   - 减少锁竞争

2. **提高吞吐量**：
   - 数据库批量操作效率更高
   - 减少事务开销

3. **资源利用**：
   - 可以集中处理，提高CPU和IO利用率

**缺点**：
1. **延迟高**：
   - 用户需要等待批量处理完成
   - 不适合实时性要求高的场景

2. **数据丢失风险**：
   - 如果服务器崩溃，未处理的批量数据可能丢失
   - 需要持久化机制

3. **内存占用**：
   - 需要缓存待处理的数据

### 13.2 实时处理

**特点**：
- 每个请求立即处理，立即返回结果

**优点**：
1. **低延迟**：
   - 用户立即得到响应
   - 体验好

2. **数据一致性**：
   - 立即写入数据库，数据实时可见
   - 减少数据丢失风险

3. **简单**：
   - 代码逻辑清晰，易于调试

**缺点**：
1. **数据库压力大**：
   - 每个请求都访问数据库
   - 高并发时可能成为瓶颈

2. **资源浪费**：
   - 频繁的小事务，开销大
   - 网络往返次数多

### 13.3 混合方案

**最佳实践**：

1. **关键操作实时处理**：
   - 用户登录、文件上传：实时处理
   - 保证用户体验

2. **非关键操作批量处理**：
   - 日志记录、统计数据：批量处理
   - 降低系统压力

3. **异步批量处理**：
   ```cpp
   // 实时：立即返回
   Response response = HandleUpload(request);
   
   // 异步：放入队列，批量处理
   LogQueue::Push(log_data);  // 日志
   StatsQueue::Push(stats_data);  // 统计
   ```

**本项目建议**：
- **文件上传**：实时处理（用户需要立即知道结果）
- **下载统计**：可以批量更新（每10秒更新一次PV）
- **日志记录**：批量写入（减少IO压力）

---

## 总结

本项目是一个完整的分布式图床系统，涉及：
- **网络编程**：Reactor模型、epoll、非阻塞IO
- **并发编程**：线程池、连接池、锁机制
- **存储系统**：FastDFS、MySQL、Redis
- **系统设计**：负载均衡、高可用、性能优化

在面试中，要能够清晰地阐述每个技术点的原理、实现方式和优化方案。
